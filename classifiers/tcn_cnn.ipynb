{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from ptcn import TemporalConvNet\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import LogHistory\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from keras.layers import Bidirectional\n",
    "import pytorch_lightning as pl\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score,recall_score\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import matplotlib.cm as cm\n",
    "from pytorch_lightning import Trainer\n",
    "import presnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"D:/罗飞/kitchen_processed_data/\"+'xall.p', 'rb')\n",
    "xall=pd.read_pickle(output,compression=None)\n",
    "output = open(\"D:/罗飞/kitchen_processed_data/\"+'yall.p', 'rb')\n",
    "yall=pd.read_pickle(output,compression=None)\n",
    "output.close()\n",
    "class_names=['Drinking',\"Eating\",\"Standing\",\"Sitting\",\"Walking\",\"Open door and get in\",\"Open door and get out\",\"Washing\",\n",
    "           \"Open oven\",\"Close oven\",\"Open cabinet\",\"Close cabinet\",\"Open freezer\",\"Close freezer\",\"No activity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "yall=le.fit_transform(yall)\n",
    "num_classes=len(np.unique(yall))\n",
    "print(np.unique(yall,return_counts=True),num_classes)\n",
    "xall, yall = shuffle(xall,yall)\n",
    "print(yall[0:15])\n",
    "x_train, x_test, y_train, y_test =train_test_split(xall, yall, test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train_tcn=keras.utils.to_categorical(y_train, num_classes=15)\n",
    "y_test_tcn=keras.utils.to_categorical(y_test, num_classes=15)\n",
    "print(x_train.shape,y_train_tcn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels,input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.pool=nn.AvgPool2d((4,4), stride=4)\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], 128)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        ###############################resnet\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=7,\n",
    "            stride=2,  # downsample with first conv\n",
    "            padding=3,\n",
    "            bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.block1=presnet._make_block(64,64,2,presnet.BasicBlock,stride=1)\n",
    "        self.block2=presnet._make_block(64,180,2,presnet.BasicBlock,stride=1)\n",
    "        ###########cat\n",
    "        self.linear2 = nn.Linear(128+180,output_size)\n",
    "        self.bnt=nn.BatchNorm1d(128)\n",
    "        self.bnc=nn.BatchNorm1d(180)\n",
    "        self.dp=nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x needs to have dimension (N, C, L) in order to be passed into CNN\n",
    "        x=x.permute(0,3,1,2)\n",
    "        pool=self.pool(x)\n",
    "        flat = pool.view(-1, 1,pool.size()[1]*pool.size()[2]*pool.size()[3])\n",
    "        tflat = self.tcn(flat)  # input should have dimension (N, C, L)\n",
    "        t = self.linear(tflat[:, :, -1])\n",
    "        t=self.bnt(t)\n",
    "        #################\n",
    "        conv=F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        conv=self.maxpool(conv)\n",
    "        conv=self.block1(conv)\n",
    "        conv=self.block2(conv)\n",
    "        conv=F.avg_pool2d(conv, (conv.size()[2],conv.size()[3]), stride=1)\n",
    "        c=conv.view(-1,conv.size()[1])\n",
    "        \n",
    "        c=self.bnc(c)\n",
    "        o = torch.cat((t, c), dim=1)\n",
    "        o=self.linear2(o)\n",
    "        o=self.dp(o)\n",
    "#         o=self.lineartest(c)\n",
    "        return F.log_softmax(o, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(x, y):\n",
    "    return TensorDataset(\n",
    "        torch.from_numpy(x).float(),\n",
    "        torch.from_numpy(y).long()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloader(x: np.array, y: np.array, batch_size: int, shuffle: bool = True, num_workers: int = 0):\n",
    "    dataset = get_dataset(x, y)\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TCNModel, self).__init__()\n",
    "        # not the best model...\n",
    "        self.val_loss=[]\n",
    "        self.val_acc=[]\n",
    "        self.l1 = TCN(in_channels=2,out_channels=64,\n",
    "                      input_size=1, output_size=15,num_channels=[25]*8,\n",
    "                      kernel_size=7, dropout=0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1.forward(x)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        yc=torch.argmax(y, dim=1)\n",
    "        train_acc = torch.sum(yc== labels_hat).float() / (len(yc) * 1.0)\n",
    "        loss=F.nll_loss(y_hat, torch.max(y, 1)[1])\n",
    "        #print('loss:', loss,'train_acc:',train_acc)\n",
    "        return {'loss': loss.type(torch.float),'train_acc':train_acc.type(torch.float)}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        yc=torch.argmax(y, dim=1)\n",
    "        val_acc = torch.sum((yc== labels_hat).float() / (len(yc) * 1.0),dtype=torch.float)\n",
    "        val_loss=F.nll_loss(y_hat, torch.max(y, 1)[1])\n",
    "        #print('val_loss:', val_loss,'val_acc:',val_acc)\n",
    "        return {'val_loss': val_loss.type(torch.float),'val_acc':val_acc}\n",
    "\n",
    "    def validation_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        self.val_loss.append(avg_loss.cpu().numpy())\n",
    "        self.val_acc.append(avg_acc.cpu().numpy())\n",
    "        print('avg_val_loss',avg_loss,'avg_val_acc', avg_acc)\n",
    "        return {'avg_val_loss': avg_loss,'avg_val_acc': avg_acc}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        return {'avg_test_loss': avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0002)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return get_dataloader(x_train, y_train_tcn, 200)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of val dataloadersdr\n",
    "        return get_dataloader(x_test, y_test_tcn,shuffle=False,batch_size=200)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        # can also return a list of test dataloaders\n",
    "        return get_dataloader(x_test, y_test_tcn,shuffle=False,batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tcnmodel = TCNModel()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "tcnmodel = tcnmodel.to(device)\n",
    "summary(tcnmodel, (80, 80,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=200, gpus=1, distributed_backend='dp')\n",
    "tcnmodel.unfreeze()\n",
    "trainer.fit(tcnmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"tcn_res_save.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc=np.array(tcnmodel.val_acc)\n",
    "val_loss=np.array(tcnmodel.val_loss)\n",
    "validation=np.transpose([val_acc,val_loss])\n",
    "print(validation.shape)\n",
    "np.savetxt(\"tcn_res_val_sysu.csv\", validation, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcnmodel.freeze()\n",
    "tcnmodel = tcnmodel.to(\"cpu\")\n",
    "\n",
    "import datetime\n",
    "txtest= torch.from_numpy(x_test[0].reshape((1,80,80,2))).float()\n",
    "print(datetime.datetime.now())\n",
    "tcnmodel(txtest)\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "txtest= torch.from_numpy(x_test[0].reshape((1,2,80,80))).float()\n",
    "print(datetime.datetime.now())\n",
    "cnn(txtest)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcnmodel.freeze()\n",
    "tcnmodel = tcnmodel.to(\"cpu\")\n",
    "txtest= torch.from_numpy(x_test).float()\n",
    "tytest= torch.from_numpy(y_test).float()\n",
    "tytest=torch.argmax(tcnmodel(txtest), dim=1)\n",
    "tyc=tytest.cpu().data.numpy()\n",
    "tyt=np.argmax(y_test_tcn, axis=1)\n",
    "print(tyt.shape)\n",
    "print(tyc.shape)\n",
    "test_acc=accuracy_score(tyt,tyc)\n",
    "test_recall=recall_score(tyt,tyc,average='macro')\n",
    "test_f1=f1_score(tyt,tyc,average=\"macro\")\n",
    "print(test_acc)\n",
    "print(test_recall)\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"tcn_res_test_sysu.csv\", np.array([test_acc,test_recall,test_f1]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,average_precision_score,confusion_matrix,recall_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    plt.figure(figsize=(24,16))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=60,fontsize=17)\n",
    "    plt.yticks(tick_marks, classes,fontsize=17)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cnf_matrix=confusion_matrix(tyt, tyc, labels=np.unique(tyt))\n",
    "np.savetxt(\"tcn_res_confusion.csv\", cnf_matrix, delimiter=\",\")\n",
    "np.set_printoptions(precision=1)\n",
    "class_names=['Drinking',\"Eating\",\"Standing\",\"Sitting\",\"Walking\",\"Open door and get in\",\"Open door and get out\",\"Washing\",\n",
    "           \"Open oven\",\"Close oven\",\"Open cabinet\",\"Close cabinet\",\"Open freezer\",\"Close freezer\",\"No activity\"]\n",
    "# Plot non-normalized confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,average_precision_score,confusion_matrix,recall_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "\n",
    "cnf_matrix=np.loadtxt('tcn_res_confusion.csv', delimiter=\",\")\n",
    "np.set_printoptions(precision=1)\n",
    "class_names=['Drinking',\"Eating\",\"Standing\",\"Sitting\",\"Walking\",\"Open door and get in\",\"Open door and get out\",\"Washing\",\n",
    "           \"Open oven\",\"Close oven\",\"Open cabinet\",\"Close cabinet\",\"Open freezer\",\"Close freezer\",\"No activity\"]\n",
    "# Plot non-normalized confusion matrix\n",
    "#plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
